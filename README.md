# DeepMARL


## Project Goal

To implement mutiple-agent reinforcement learning (MARL) by using distributed DQN agents to train in a dynamic, cooperative, and comptetitive grid environment.
The goal of each agent may be to survive, compete and accumulate reward, and as societies of agents compete and acculumate reward.


- Researched RL agents, specifically DQN variations and those utilizing a distributed architecture.
- Researched DQN taxonomy and composition using YouTube and example code.
- Researched various 'game-engines' that can be used with DQN agents: OpenAI Gym, PyGame.
- Researched environments, particularly Neural MMO, a massively multiagent game environment.
  - Think of a extremely basic MineCraft server, used to render terrain, agents, resources as a sort of sandbox environment.
- Implemented rudimentary single-agent using OpenAI polecart in order to familiarize with pilepine and relevant parameters.
- Ran through one example using polecart in order to familarize with the process and tf-agent module
- Run through second and distill process into my own implementation
- Ok, so I've a decision to make. Simply switching enviros is nogo because FrozenLake breaks too much of the current implementation and would require a possibly expensive expenditure of time given that Frozen Lake is only supposed to be an example, a proof of concept so to speak. At this juncture I could push into that, and I think I may eventually regardless for presentation effect in order to present the basic concepts before unveiling mmo enviro. For now, I think I'll go ahead and make the switch to the ult. goal of working in mmo, even if this means learning to implement agent etc in new enviro and ...
- wow. So I went and tried implemnting an environment, first and Neural-mmo then using OpenAi enviro for their emergent multi-agent demo from last year - both failed miserab-- actually, I was able to get neural up and running, it just didn't seem to provide enough, or enough clearly labelled, space for me to implement and experiment my project in. The OpenAi demo failed on the install - and both took far too much effort/time.
- I'm looking at how to implement at least DQN in an enviro for stock market prediction, yes, going back but this'll save time on the implementation and I'll be ble to do more work with time series and also have the financial spot in my portfolio filled, along with some ML and the RL will be nice. I anticipate another time savings with my better understanding of jinja/front end.
- implement.




Currently


The current plan is to:
- Learn a few implementations of RL for stock market. noting features to have

- Add whatever features are needed for the visual
- Make visual
- Readme
- More features



To Do's:
- Collect helpers, including saving and accessing agents